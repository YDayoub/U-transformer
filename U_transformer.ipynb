{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMt9+6DFErWuXa2cJMdhNRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YDayoub/U-transformer/blob/main/U_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NsHozpzlIsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ff6c0d-6a78-48e5-c177-beb325560b5e"
      },
      "source": [
        "'''\n",
        "Import required libraries\n",
        "\n",
        "'''\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "from functools import partial\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekrbb2GkSKiJ"
      },
      "source": [
        "batch_size = 128          \n",
        "test_batch_size = 128   \n",
        "epochs = 15             \n",
        "lr = 5e-4               \n",
        "seed = 42               \n",
        "h_dims = 16\n",
        "n_heads = 2\n",
        "n_blocks = 2\n",
        "dropout = 0.1\n",
        "clip = 5"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsvxLamYx-zF"
      },
      "source": [
        "'''\n",
        "This code is adapted from \n",
        "https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html\n",
        "'''\n",
        "class Embedding_with_PosEncoding(nn.Module):\n",
        "  def __init__(self,input_dim,d_model, max_len=5000,dropout=0):\n",
        "    '''\n",
        "    Args:\n",
        "      d_model: hidden space dimentionality for Embedding\n",
        "      input_dim: input space dimentionality\n",
        "      max_len: maximum length of an input sequence\n",
        "      drop: probability of an element to be zeroed\n",
        "    '''\n",
        "    super(Embedding_with_PosEncoding,self).__init__()\n",
        "    self.emb = nn.Linear(in_features=input_dim,out_features = d_model)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    # register_buffer is used to save and retrain parameters which don't need to train\n",
        "    self.register_buffer('pe', pe, persistent=False) \n",
        "  def forward(self,x):\n",
        "    seq_len = x.size(1)\n",
        "    x = self.emb(x)\n",
        "    x = self.dropout(x)\n",
        "    x = x + self.pe[:, :seq_len]\n",
        "    return x\n",
        "  def get_pe(self):\n",
        "    return self.pe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2k37K8dSjZB"
      },
      "source": [
        "def test_positional_encoding():\n",
        "  batch_dim,seq_len,input_dim= (15,10,200)\n",
        "  d_model = 100\n",
        "  max_len =100\n",
        "  x = torch.randn(batch_dim,seq_len, input_dim)\n",
        "  pos_encoder = Embedding_with_PosEncoding(input_dim,d_model,max_len)\n",
        "  pe = pos_encoder.get_pe()\n",
        "  res = pos_encoder(x)\n",
        "  assert res.shape ==  torch.Size([batch_dim,seq_len,d_model])\n",
        "  assert pe.shape == torch.Size([1, max_len, d_model])\n",
        "test_positional_encoding()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9NzV-cFUbdz"
      },
      "source": [
        "def scaled_dot_product(query,key,values,mask=None,scale=True):\n",
        "  '''\n",
        "      Args:\n",
        "        query: tensor of queries\n",
        "        key : tensor of keys\n",
        "        value: tensor of value\n",
        "        mask (numpy.ndarray): attention-mask, used to perform self attention when required\n",
        "        scale (bool): whether to scale the dot product of the query and transposed key\n",
        "  '''\n",
        "  if scale:\n",
        "    depth = query.shape[-1] ** 0.5\n",
        "  else:\n",
        "    depth = 1\n",
        "  dots = torch.matmul(query,torch.swapaxes(key,-1,-2))/depth\n",
        "  if mask is not None:\n",
        "    dots = torch.where(mask,dots,torch.full_like(dots, -9e15))\n",
        "  logsumexp = torch.logsumexp(dots, axis=-1, keepdims=True)\n",
        "  dots = torch.exp(dots - logsumexp)\n",
        "  attention = torch.matmul(dots, values)\n",
        "  return attention\n",
        "def dot_product_self_attention(q, k, v,device=device):\n",
        "  '''\n",
        "    Args:\n",
        "        q: queries.\n",
        "        k: keys.\n",
        "        v: values.\n",
        "    Returns:\n",
        "        masked dot product self attention tensor.  \n",
        "  '''\n",
        "  mask_size = q.shape[-2]\n",
        "  mask = torch.tril(torch.ones((1, mask_size, mask_size), dtype=torch.bool), diagonal=0).to(device)        \n",
        "  return scaled_dot_product(q, k, v, mask)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gA0CRdjiU8H"
      },
      "source": [
        "class QKV(nn.Module):\n",
        "  '''\n",
        "  takes as input a tensor of shape (batch_size,seq_len,d_model)\n",
        "  returns:\n",
        "  three tensors q,k,v of shape (batch_size,n_heads,seq_len,d_model//n_heads)\n",
        "  '''\n",
        "\n",
        "  def __init__(self,n_heads,d_model):\n",
        "    '''\n",
        "      Args:\n",
        "        n_heads: number of heads used in multihead attention\n",
        "        d_model: hidden space dimensions\n",
        "    '''\n",
        "    assert d_model%n_heads==0,'d_models should be divisible by n_heads'\n",
        "    super(QKV,self).__init__()\n",
        "    self.qvk = nn.Linear(in_features=d_model,out_features=3*d_model)\n",
        "    self.d_model = d_model\n",
        "    self.n_heads = n_heads\n",
        "    self.d_heads = d_model//n_heads\n",
        "  def forward(self,x):\n",
        "    batch_size,seq_len,d_model = x.shape\n",
        "    x = self.qvk(x)\n",
        "    x = x.reshape(batch_size,seq_len,self.n_heads,3*self.d_heads)\n",
        "    x = x.permute(0,2,1,3)\n",
        "    q,k,v = x.chunk(3,dim=-1)\n",
        "    return q,k,v\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9JEfLDB7oW_"
      },
      "source": [
        "def test_QKV():\n",
        "  batch_dim,seq_len,d_model= (15,10,200)\n",
        "  n_heads = 2\n",
        "  x = torch.randn(batch_dim,seq_len, d_model).to(device)\n",
        "  qkv = QKV(n_heads=n_heads,d_model=d_model).to(device)\n",
        "  q,k,v = qkv(x)\n",
        "  assert q.shape ==  torch.Size([batch_dim, n_heads, seq_len,d_model//n_heads])\n",
        "  assert k.shape ==  torch.Size([batch_dim, n_heads, seq_len,d_model//n_heads])\n",
        "  assert v.shape ==  torch.Size([batch_dim, n_heads, seq_len,d_model//n_heads])\n",
        "test_QKV()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CR3TtPk2wnr"
      },
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  '''\n",
        "  This class implements mulithead attention\n",
        "  '''\n",
        "  def __init__(self,d_model,causal_attention=False):\n",
        "    '''\n",
        "      Args:\n",
        "        d_model: hidden space dimensions\n",
        "        causal_attention: boolean whether to use attention or causal attention \n",
        "    '''\n",
        "    super(MultiheadAttention,self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.o = nn.Linear(in_features=d_model,out_features=d_model)\n",
        "    self.causal_attention = causal_attention \n",
        "\n",
        "  def forward(self,q,k,v):\n",
        "    batch_size,n_heads,seq_len,d_heads = q.shape\n",
        "    if self.causal_attention:\n",
        "      atten =  dot_product_self_attention(q, k, v)\n",
        "    else:\n",
        "      atten = scaled_dot_product(q,k,v)\n",
        "    atten = atten.permute(0,2,1,3)\n",
        "    atten = atten.reshape(batch_size,seq_len,self.d_model)\n",
        "    res = self.o(atten)\n",
        "    return res\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTh48ZAH8mSw"
      },
      "source": [
        "def test_MultiheadAttention():\n",
        "  batch_dim,seq_len,d_model= (15,10,200)\n",
        "  n_heads = 2\n",
        "  att = MultiheadAttention(d_model,causal_attention=False).to(device)\n",
        "  causal_att = MultiheadAttention(d_model,causal_attention=True).to(device)\n",
        "  x = torch.randn(batch_dim, n_heads, seq_len,3,d_model//n_heads).to(device)\n",
        "  q,k,v = x[:,:,:,0,:],x[:,:,:,1,:],x[:,:,:,2,:]\n",
        "  o1 = att(q,k,v)\n",
        "  o2 = causal_att(q,k,v)\n",
        "  assert o1.shape ==  torch.Size([batch_dim, seq_len,d_model])\n",
        "  assert o2.shape ==  torch.Size([batch_dim,  seq_len,d_model])\n",
        "test_MultiheadAttention()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTC9-skP2ory"
      },
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  '''\n",
        "  This class implements encoder block\n",
        "  '''\n",
        "  def __init__(self,d_model, n_heads, dim_feedforward, dropout=0.0):\n",
        "    '''\n",
        "      Args:\n",
        "        d_model: hidden space dimensions\n",
        "        n_heads: number of heads\n",
        "        dim_feedforward: Dimensionality of the hidden layer in the MLP  \n",
        "        drop: probability of an element to be zeroed\n",
        "    '''\n",
        "    super(EncoderBlock,self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.qkv =  QKV(n_heads=n_heads,d_model=d_model)\n",
        "    self.attention = MultiheadAttention(d_model=d_model,causal_attention=False)\n",
        "    self.feedforward = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_feedforward),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim_feedforward, d_model)\n",
        "        )\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self,x0):\n",
        "    q,k,v = self.qkv(x0)\n",
        "    x1 = self.attention(q,k,v)\n",
        "    x2 = self.norm1(x0+self.dropout(x1))\n",
        "    x3 = self.feedforward(x2)\n",
        "    x4 = self.norm2(self.dropout(x3)+x2)\n",
        "    return x4\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyWmFwuHFO46"
      },
      "source": [
        "def reshape_tensor(x,n_heads):\n",
        "  '''\n",
        "    Args:\n",
        "      x: tensor of shape (batch_size,seq_len,d_model)\n",
        "      n_heads: number of heads in mutlihead attention\n",
        "    Returns:\n",
        "      reshaped tensor of shape (batch_size,n_heads,seq_len,d_model//n_heads)    \n",
        "  '''\n",
        "  batch_size,seq_len,d_model = x.shape\n",
        "  x = x.reshape(batch_size,seq_len,n_heads,d_model//n_heads)\n",
        "  x = x.permute(0,2,1,3)\n",
        "  return x\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "  '''\n",
        "    This class implements decoder block\n",
        "  '''\n",
        "\n",
        "  def __init__(self,d_model, n_heads, dim_feedforward, dropout=0.0):\n",
        "    '''\n",
        "      Args:\n",
        "        d_model: hidden space dimensions\n",
        "        n_heads: number of heads\n",
        "        dim_feedforward: Dimensionality of the hidden layer in the MLP  \n",
        "        drop: probability of an element to be zeroed\n",
        "    '''\n",
        "    super(DecoderBlock,self).__init__()\n",
        "    self.n_heads = n_heads\n",
        "    self.d_model = d_model\n",
        "    self.qkv = QKV(n_heads,d_model)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.attention = MultiheadAttention(d_model,causal_attention=False)\n",
        "    self.causal_attention = MultiheadAttention(d_model,causal_attention=True)\n",
        "    self.feedforward = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_feedforward),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim_feedforward, d_model)\n",
        "        )\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "    self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self,x0,skip_con):\n",
        "    q,k,v = self.qkv(x0)\n",
        "    x1 = self.attention(q,k,v)\n",
        "    x2 = self.norm1(x0+self.dropout(x1))\n",
        "    x3 = reshape_tensor(x2,self.n_heads)\n",
        "    skip_con = reshape_tensor(skip_con,self.n_heads)\n",
        "    x4 = self.causal_attention(x3,skip_con,skip_con)\n",
        "    x5 = self.norm2(x2+self.dropout(x4))\n",
        "    x6 = self.feedforward(x5)\n",
        "    x7 = self.norm3(self.dropout(x6)+x5)\n",
        "    return x7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUG1NMhDKAvw"
      },
      "source": [
        "class UnetTransformer(nn.Module):\n",
        "  '''\n",
        "    This class implements unet transformer\n",
        "  '''\n",
        "  def __init__(self,n_blocks,input_dim,n_heads,d_model,num_classes,dim_feedforward,dropout=0.0):\n",
        "\n",
        "    '''\n",
        "      Args:\n",
        "        n_blocks: number of encoder/decoder blocks\n",
        "        input_dim: Dimensionality of the input space\n",
        "        n_heads: number of heads in MultiHeadAttention\n",
        "        d_model: Dimensionality of the embedding space\n",
        "        num_classes: Dimensionality of the output space\n",
        "        dim_feedforward:  Dimensionality of the hidden layer in the MLP \n",
        "\n",
        "\n",
        "    '''\n",
        "    super(UnetTransformer,self).__init__()\n",
        "    self.n_blocks = n_blocks\n",
        "    self.pos_enc = Embedding_with_PosEncoding(input_dim,d_model,dropout=dropout)\n",
        "    for i in range(n_blocks):\n",
        "      vars(self)['_modules']['enc_'+str(i)] = EncoderBlock(d_model, n_heads, dim_feedforward, dropout)\n",
        "    for i in range(n_blocks):\n",
        "      vars(self)['_modules']['dec_'+str(i)] = DecoderBlock(d_model, n_heads, dim_feedforward, dropout)\n",
        "    self.output_layer = nn.Sequential( nn.Linear(d_model, d_model),\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model, num_classes)\n",
        "        )\n",
        "  def forward(self,x):\n",
        "    x_encoded = self.pos_enc(x)\n",
        "    layers = vars(self)['_modules']\n",
        "    stack = [x_encoded]\n",
        "    x = layers['enc_0'](x_encoded)\n",
        "    for i in range(1,self.n_blocks):\n",
        "      stack.append(x)\n",
        "      x = layers['enc_'+str(i)](x)\n",
        "    for i in range(self.n_blocks):\n",
        "      x = layers['dec_'+str(i)](x,stack.pop())\n",
        "    return self.output_layer(x)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndJCTLgBuQHp"
      },
      "source": [
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "  model.train()\n",
        "  num_classes = train_loader.dataset.num_categories\n",
        "  l = 0\n",
        "  acc = 0\n",
        "  pbar = tqdm(total = len(train_loader),position=0,leave=True)\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data = F.one_hot(data, num_classes=num_classes).float()\n",
        "    optimizer.zero_grad()        \n",
        "    preds = model(data)        \n",
        "    loss = criterion(preds.view(-1,preds.size(-1)), target.view(-1),reduction=\"mean\")\n",
        "    loss.backward() \n",
        "    #nn.utils.clip_grad_norm(model.parameters(), clip)       \n",
        "    optimizer.step()\n",
        "    with torch.no_grad():\n",
        "      current_loss = loss.item()\n",
        "      l+= loss.item()\n",
        "      acc+=(preds.argmax(dim=-1) == target).float().mean().item()\n",
        "    pbar.set_description('training_step {} loss:{:3f}'.format(batch_idx,current_loss))\n",
        "    pbar.update()\n",
        "  acc = 100. * acc / (len(train_loader))\n",
        "  l = l/len(train_loader)\n",
        "  print('{0}: loss: {1:.3f} acc {2:.1f}'.format('train',l,acc))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOzqXY-WwNlr"
      },
      "source": [
        "def test( model, device, test_loader,criterion,mode='eval'):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  num_classes=test_loader.dataset.num_categories\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          data = F.one_hot(data, num_classes=num_classes).float()  \n",
        "          output = model(data)\n",
        "          test_loss += criterion(output.view(-1,output.size(-1)),\\\n",
        "                                        target.view(-1)).item()          \n",
        "          correct += (output.argmax(dim=-1) == target).float().mean().item()\n",
        "\n",
        "  loss = test_loss/len(test_loader)\n",
        "  acc = 100. * correct / len(test_loader)\n",
        "  print('{0}: loss: {1:.3f} acc {2:.1f}'.format(mode,loss,acc))\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raohC_7iRk0N"
      },
      "source": [
        "class ReverseDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, num_categories, seq_len, size):\n",
        "        super().__init__()\n",
        "        self.num_categories = num_categories\n",
        "        self.seq_len = seq_len\n",
        "        self.size = size\n",
        "\n",
        "        self.data = torch.randint(self.num_categories, size=(self.size, self.seq_len))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inp_data = self.data[idx]\n",
        "        labels = torch.flip(inp_data, dims=(0,))\n",
        "        return inp_data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ8jEEssRQX5",
        "outputId": "2a42814f-b893-458e-df04-635b9ca67105"
      },
      "source": [
        "def main():\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.determinstic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    dataset = partial(ReverseDataset, 10, 16)\n",
        "    train_loader = data.DataLoader(dataset(50000), batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
        "\n",
        "    val_loader   = data.DataLoader(dataset(1000), batch_size=test_batch_size)\n",
        "    test_loader  = data.DataLoader(dataset(10000), batch_size=test_batch_size)\n",
        "    model = UnetTransformer(n_blocks=n_blocks,input_dim=train_loader.dataset.num_categories,\\\n",
        "                            n_heads=n_heads,d_model = h_dims,num_classes=\\\n",
        "                            train_loader.dataset.num_categories,dim_feedforward = h_dims,\\\n",
        "                            dropout=dropout).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr= lr)\n",
        "    criterion =  F.cross_entropy\n",
        "    \n",
        "\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "       train(model, device, train_loader, optimizer,criterion)\n",
        "       test(model, device, val_loader,criterion)\n",
        "        \n",
        "    torch.save(model.state_dict(), \"model.h5\")\n",
        "    print('------------testing--------------')\n",
        "    test(model, device, test_loader,criterion,mode='test')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:1.737720: 100%|██████████| 390/390 [00:07<00:00, 54.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 2.237 acc 15.1\n",
            "eval: loss: 1.562 acc 48.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.198213: 100%|██████████| 390/390 [00:07<00:00, 54.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.660 acc 83.9\n",
            "eval: loss: 0.083 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.078665: 100%|██████████| 390/390 [00:07<00:00, 54.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.122 acc 98.6\n",
            "eval: loss: 0.014 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.039562: 100%|██████████| 390/390 [00:07<00:00, 53.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.052 acc 99.3\n",
            "eval: loss: 0.004 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.033151: 100%|██████████| 390/390 [00:07<00:00, 53.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.033 acc 99.5\n",
            "eval: loss: 0.002 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.021332: 100%|██████████| 390/390 [00:07<00:00, 54.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.025 acc 99.6\n",
            "eval: loss: 0.001 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.017049: 100%|██████████| 390/390 [00:07<00:00, 54.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.019 acc 99.7\n",
            "eval: loss: 0.000 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.015821: 100%|██████████| 390/390 [00:07<00:00, 54.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.015 acc 99.7\n",
            "eval: loss: 0.000 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.011333: 100%|██████████| 390/390 [00:07<00:00, 54.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.013 acc 99.7\n",
            "eval: loss: 0.000 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.009495: 100%|██████████| 390/390 [00:07<00:00, 54.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.011 acc 99.8\n",
            "eval: loss: 0.000 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.007387: 100%|██████████| 390/390 [00:07<00:00, 54.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.010 acc 99.8\n",
            "eval: loss: 0.000 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.005797: 100%|██████████| 390/390 [00:07<00:00, 54.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.008 acc 99.8\n",
            "eval: loss: 0.000 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.008655: 100%|██████████| 390/390 [00:07<00:00, 53.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.008 acc 99.8\n",
            "eval: loss: 0.000 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.008578: 100%|██████████| 390/390 [00:07<00:00, 54.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.007 acc 99.8\n",
            "eval: loss: 0.000 acc 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training_step 389 loss:0.003324: 100%|██████████| 390/390 [00:07<00:00, 54.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: loss: 0.006 acc 99.8\n",
            "eval: loss: 0.000 acc 100.0\n",
            "------------testing--------------\n",
            "test: loss: 0.000 acc 100.0\n"
          ]
        }
      ]
    }
  ]
}