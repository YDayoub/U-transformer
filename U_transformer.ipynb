{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlbYQsIDmvXrc1bC0ceQBV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YDayoub/U-transformer/blob/main/U_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NsHozpzlIsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba4af48-46ce-4320-c5a6-ed6ca78d3ebf"
      },
      "source": [
        "'''\n",
        "Import required libraries\n",
        "'''\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "from functools import partial\n",
        "import math\n",
        "from typing import Tuple\n",
        "import os\n",
        "import random\n",
        "from torch.utils.data import dataset\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekrbb2GkSKiJ"
      },
      "source": [
        "# batch_size = 128          \n",
        "# test_batch_size = 128   \n",
        "epochs = 100             \n",
        "lr = 5e-4               \n",
        "seed = 42               \n",
        "h_dims = 1024\n",
        "n_heads = 16\n",
        "n_blocks = 2\n",
        "dropout = 0.1\n",
        "out_dropout = 0.4\n",
        "emb_dropout = 0.1\n",
        "clip = 0.5\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "bptt = 256\n",
        "d_model = 400"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "set_seed(seed)"
      ],
      "metadata": {
        "id": "y8wnlsR8KR5p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalConv1d(nn.Module):\n",
        "  def __init__(self, d_model, kernel_size=3, dilation=1, **kwargs):\n",
        "    pad = (kernel_size - 1) * dilation\n",
        "    self.conv = nn.Conv1d(d_model, d_model, kernel_size, padding=pad, dilation=dilation, groups=d_model, **kwargs)\n",
        "  def forward(self,x):\n",
        "    ''''\n",
        "    x has shape of batch_size, seq_len, d_model\n",
        "    '''\n",
        "    x = x.transpose(2,1) # now shape is [batch_size, d_model, seq_len]\n",
        "    x = self.conv1(x)\n",
        "    x = x[:, :, :-self.conv1.padding[0]]\n",
        "    x = x.transpose(2,1)\n",
        "    return x.contiguous()\n"
      ],
      "metadata": {
        "id": "cFR8anxGJTDy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import TransformerEncoderLayer, TransformerDecoderLayer\n",
        "import math\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        # register_buffer is used to save and retrain parameters which don't need to train\n",
        "        self.register_buffer('pe', pe, persistent=False) \n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
        "        \"\"\"\n",
        "        seq_len = x.size(1)\n",
        "        x = x + self.pe[:, :seq_len]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "inWGWGwa6z-_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsvxLamYx-zF"
      },
      "source": [
        "# '''\n",
        "# This code is adapted from \n",
        "# https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html\n",
        "# '''\n",
        "# class Embedding_with_PosEncoding(nn.Module):\n",
        "#   def __init__(self,input_dim,d_model, max_len=5000,dropout=0):\n",
        "#     '''\n",
        "#     Args:\n",
        "#       d_model: hidden space dimentionality for Embedding\n",
        "#       input_dim: input space dimentionality\n",
        "#       max_len: maximum length of an input sequence\n",
        "#       drop: probability of an element to be zeroed\n",
        "#     '''\n",
        "#     super(Embedding_with_PosEncoding,self).__init__()\n",
        "#     self.emb = nn.Embedding(input_dim,d_model)\n",
        "#     self.dropout = nn.Dropout(p=dropout)\n",
        "#     pe = torch.zeros(max_len, d_model)\n",
        "#     position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "#     div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "#     pe[:, 0::2] = torch.sin(position * div_term)\n",
        "#     pe[:, 1::2] = torch.cos(position * div_term)\n",
        "#     pe = pe.unsqueeze(0)\n",
        "#     # register_buffer is used to save and retrain parameters which don't need to train\n",
        "#     self.register_buffer('pe', pe, persistent=False) \n",
        "#   def forward(self,x):\n",
        "#     seq_len = x.size(1)\n",
        "#     x = self.emb(x)\n",
        "#     x = self.dropout(x)\n",
        "#     x = x + self.pe[:, :seq_len]\n",
        "#     return x\n",
        "#   def get_pe(self):\n",
        "#     return self.pe"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2k37K8dSjZB"
      },
      "source": [
        "# def test_positional_encoding():\n",
        "#   batch_dim,seq_len,input_dim= (15,10,10)\n",
        "#   d_model = 100\n",
        "#   max_len =100\n",
        "#   x = torch.randint(low=0, high=10,size=(batch_dim,seq_len))\n",
        "#   pos_encoder = Embedding_with_PosEncoding(input_dim,d_model,max_len)\n",
        "#   pe = pos_encoder.get_pe()\n",
        "#   res = pos_encoder(x)\n",
        "#   assert res.shape ==  torch.Size([batch_dim,seq_len,d_model])\n",
        "#   assert pe.shape == torch.Size([1, max_len, d_model])\n",
        "# test_positional_encoding()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9NzV-cFUbdz"
      },
      "source": [
        "def scaled_dot_product(query,key,values,mask=None,scale=True):\n",
        "  '''\n",
        "      Args:\n",
        "        query: tensor of queries\n",
        "        key : tensor of keys\n",
        "        value: tensor of value\n",
        "        mask (numpy.ndarray): attention-mask, used to perform self attention when required\n",
        "        scale (bool): whether to scale the dot product of the query and transposed key\n",
        "  '''\n",
        "  if scale:\n",
        "    depth = query.shape[-1] ** 0.5\n",
        "  else:\n",
        "    depth = 1\n",
        "  dots = torch.matmul(query,torch.swapaxes(key,-1,-2))/depth\n",
        "  if mask is not None:\n",
        "    dots = torch.where(mask,dots,torch.full_like(dots, -9e15))\n",
        "  logsumexp = torch.logsumexp(dots, axis=-1, keepdims=True)\n",
        "  dots = torch.exp(dots - logsumexp)\n",
        "  #dots = torch.sigmoid(dots)\n",
        "  attention = torch.matmul(dots, values)\n",
        "  return attention\n",
        "def dot_product_self_attention(q, k, v,device=device):\n",
        "  '''\n",
        "    Args:\n",
        "        q: queries.\n",
        "        k: keys.\n",
        "        v: values.\n",
        "    Returns:\n",
        "        masked dot product self attention tensor.  \n",
        "  '''\n",
        "  mask_size = q.shape[-2]\n",
        "  mask = torch.tril(torch.ones((1, mask_size, mask_size), dtype=torch.bool), diagonal=0).to(device)        \n",
        "  return scaled_dot_product(q, k, v, mask)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gA0CRdjiU8H"
      },
      "source": [
        "class se_block(nn.Module):\n",
        "  def __init__(self, n_heads):\n",
        "    super().__init__()\n",
        "    self.n_heads = n_heads\n",
        "    assert n_heads>=4, 'n_heads should be bigger than 4'\n",
        "    self.lin1 = nn.Linear(n_heads, n_heads//4)\n",
        "    self.lin2 = nn.Linear(n_heads//4, n_heads)\n",
        "    self.sig = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    '''\n",
        "    x has shape batch_size,seq_len,self.n_heads,self.d_heads\n",
        "    '''\n",
        "    inputs = x\n",
        "    x = torch.mean(x, dim=-1, keepdim=False)\n",
        "    x = self.relu(self.lin1(x))\n",
        "    x = self.sig(self.lin2(x))\n",
        "    x = inputs*x.unsqueeze(-1)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class QKV(nn.Module):\n",
        "  '''\n",
        "  takes as input a tensor of shape (batch_size,seq_len,d_model)\n",
        "  returns:\n",
        "  three tensors q,k,v of shape (batch_size,n_heads,seq_len,d_model//n_heads)\n",
        "  '''\n",
        "\n",
        "  def __init__(self,n_heads,d_model):\n",
        "    '''\n",
        "      Args:\n",
        "        n_heads: number of heads used in multihead attention\n",
        "        d_model: hidden space dimensions\n",
        "    '''\n",
        "    assert d_model%n_heads==0,'d_models should be divisible by n_heads'\n",
        "    super(QKV,self).__init__()\n",
        "    #self.qvk = nn.Linear(in_features=d_model,out_features=2*d_model)\n",
        "    self.q = nn.Sequential(nn.Linear(in_features=d_model,out_features=d_model//2, bias=False),\\\n",
        "                             nn.ReLU(),\n",
        "                             nn.Linear(in_features=d_model//2,out_features=d_model,bias=False))\n",
        "    self.k = nn.Sequential(nn.Linear(in_features=d_model,out_features=d_model//2, bias=False),\\\n",
        "                             nn.ReLU(),\n",
        "                             nn.Linear(in_features=d_model//2,out_features=d_model,bias=False))\n",
        "    self.v = nn.Sequential(nn.Linear(in_features=d_model,out_features=d_model//2),\\\n",
        "                             nn.ReLU(),\n",
        "                             nn.Linear(in_features=d_model//2,out_features=d_model))\n",
        "    self.d_model = d_model\n",
        "    self.n_heads = n_heads\n",
        "    self.d_heads = d_model//n_heads\n",
        "    self.q_se = se_block(n_heads)\n",
        "    self.k_se = se_block(n_heads)\n",
        "    self.v_se = se_block(n_heads)\n",
        "\n",
        "  def forward(self,x):\n",
        "    batch_size,seq_len,d_model = x.shape\n",
        "    q = self.q(x)\n",
        "    k = self.k(x)\n",
        "    v = self.v(x)\n",
        "    x = torch.cat([q,k,v],dim=-1)\n",
        "    x = x.reshape(batch_size,seq_len,self.n_heads,3*self.d_heads)\n",
        "    q,k,v = x.chunk(3,dim=-1)\n",
        "    q = self.q_se(q)\n",
        "    k =self.k_se(k)\n",
        "    v = self.v_se(v)\n",
        "    x = torch.cat([q,k,v],dim=-1)\n",
        "    x = x.permute(0,2,1,3)\n",
        "    return  x.chunk(3,dim=-1)\n",
        "\n",
        "def test_QKV():\n",
        "  batch_dim,seq_len,d_model= (15,10,200)\n",
        "  n_heads = 4\n",
        "  x = torch.randn(batch_dim,seq_len, d_model).to(device)\n",
        "  qkv = QKV(n_heads=n_heads,d_model=d_model).to(device)\n",
        "  q,k,v = qkv(x)\n",
        "  assert q.shape ==  torch.Size([batch_dim, n_heads, seq_len,d_model//n_heads])\n",
        "  assert k.shape ==  torch.Size([batch_dim, n_heads, seq_len,d_model//n_heads])\n",
        "  assert v.shape ==  torch.Size([batch_dim, n_heads, seq_len,d_model//n_heads])\n",
        "  del q,k,v\n",
        "test_QKV()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CR3TtPk2wnr"
      },
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  '''\n",
        "  This class implements mulithead attention\n",
        "  '''\n",
        "  def __init__(self,d_model,causal_attention=False):\n",
        "    '''\n",
        "      Args:\n",
        "        d_model: hidden space dimensions\n",
        "        causal_attention: boolean whether to use attention or causal attention \n",
        "    '''\n",
        "    super(MultiheadAttention,self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.o = nn.Linear(in_features=d_model,out_features=d_model)\n",
        "    self.causal_attention = causal_attention \n",
        "\n",
        "  def forward(self,q,k,v):\n",
        "    batch_size,n_heads,seq_len,d_heads = q.shape\n",
        "    if self.causal_attention:\n",
        "      atten =  dot_product_self_attention(q, k, v)\n",
        "    else:\n",
        "      atten = scaled_dot_product(q,k,v)\n",
        "    atten = atten.permute(0,2,1,3)\n",
        "    atten = atten.reshape(batch_size,seq_len,self.d_model)\n",
        "    res = self.o(atten)\n",
        "    return res\n",
        "def test_MultiheadAttention():\n",
        "  batch_dim,seq_len,d_model= (15,10,200)\n",
        "  n_heads = 2\n",
        "  att = MultiheadAttention(d_model,causal_attention=False).to(device)\n",
        "  causal_att = MultiheadAttention(d_model,causal_attention=True).to(device)\n",
        "  x = torch.randn(batch_dim, n_heads, seq_len,3,d_model//n_heads).to(device)\n",
        "  q,k,v = x[:,:,:,0,:],x[:,:,:,1,:],x[:,:,:,2,:]\n",
        "  o1 = att(q,k,v)\n",
        "  o2 = causal_att(q,k,v)\n",
        "  assert o1.shape ==  torch.Size([batch_dim, seq_len,d_model])\n",
        "  assert o2.shape ==  torch.Size([batch_dim,  seq_len,d_model])\n",
        "  del o1,o2,q,k,v\n",
        "test_MultiheadAttention()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTC9-skP2ory"
      },
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  '''\n",
        "  This class implements encoder block\n",
        "  '''\n",
        "  def __init__(self,d_model, n_heads, dim_feedforward, dropout=0.0):\n",
        "    '''\n",
        "      Args:\n",
        "        d_model: hidden space dimensions\n",
        "        n_heads: number of heads\n",
        "        dim_feedforward: Dimensionality of the hidden layer in the MLP  \n",
        "        drop: probability of an element to be zeroed\n",
        "    '''\n",
        "    super(EncoderBlock,self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.qkv =  QKV(n_heads=n_heads,d_model=d_model)\n",
        "    self.attention = MultiheadAttention(d_model=d_model,causal_attention=True)\n",
        "    self.feedforward = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_feedforward),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim_feedforward, d_model)\n",
        "        )\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self,x0):\n",
        "    q,k,v = self.qkv(x0)\n",
        "    x1 = self.attention(q,k,v)\n",
        "    x2 = self.norm1(x0+self.dropout(x1))\n",
        "    x3 = self.feedforward(x2)\n",
        "    x4 = self.norm2(self.dropout(x3)+x2)\n",
        "    return x4\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyWmFwuHFO46"
      },
      "source": [
        "def reshape_tensor(x,n_heads):\n",
        "  '''\n",
        "    Args:\n",
        "      x: tensor of shape (batch_size,seq_len,d_model)\n",
        "      n_heads: number of heads in mutlihead attention\n",
        "    Returns:\n",
        "      reshaped tensor of shape (batch_size,n_heads,seq_len,d_model//n_heads)    \n",
        "  '''\n",
        "  batch_size,seq_len,d_model = x.shape\n",
        "  x = x.reshape(batch_size,seq_len,n_heads,d_model//n_heads)\n",
        "  x = x.permute(0,2,1,3)\n",
        "  return x\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "  '''\n",
        "    This class implements decoder block\n",
        "  '''\n",
        "\n",
        "  def __init__(self,d_model, n_heads, dim_feedforward, dropout=0.0):\n",
        "    '''\n",
        "      Args:\n",
        "        d_model: hidden space dimensions\n",
        "        n_heads: number of heads\n",
        "        dim_feedforward: Dimensionality of the hidden layer in the MLP  \n",
        "        drop: probability of an element to be zeroed\n",
        "    '''\n",
        "    super(DecoderBlock,self).__init__()\n",
        "    self.n_heads = n_heads\n",
        "    self.d_model = d_model\n",
        "    self.qkv = QKV(n_heads,d_model)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.attention = MultiheadAttention(d_model,causal_attention=True)\n",
        "    self.causal_attention = MultiheadAttention(d_model,causal_attention=True)\n",
        "    self.feedforward = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_feedforward),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim_feedforward, d_model)\n",
        "        )\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "    self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self,x0,skip_con):\n",
        "    q,k,v = self.qkv(x0)\n",
        "    x1 = self.causal_attention(q,k,v)\n",
        "    x2 = self.norm1(x0+self.dropout(x1))\n",
        "    x3 = reshape_tensor(x2,self.n_heads)\n",
        "    skip_con = reshape_tensor(skip_con,self.n_heads)\n",
        "    x4 = self.attention(x3,skip_con,skip_con)\n",
        "    x5 = self.norm2(x2+self.dropout(x4))\n",
        "    x6 = self.feedforward(x5)\n",
        "    x7 = self.norm3(self.dropout(x6)+x5)\n",
        "    return x7"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUG1NMhDKAvw"
      },
      "source": [
        "class UnetTransformer(nn.Module):\n",
        "  '''\n",
        "    This class implements unet transformer\n",
        "  '''\n",
        "  def __init__(self,n_blocks,n_tokens,n_heads,d_model,dim_feedforward,emb_dropout=0.2,\\\n",
        "               out_dropout = 0.4, dropout=0.2):\n",
        "\n",
        "    '''\n",
        "      Args:\n",
        "        n_blocks: number of encoder/decoder blocks\n",
        "        n_tokens: Dimensionality of the input space\n",
        "        n_heads: number of heads in MultiHeadAttention\n",
        "        d_model: Dimensionality of the embedding space\n",
        "        num_classes: Dimensionality of the output space\n",
        "        dim_feedforward:  Dimensionality of the hidden layer in the MLP \n",
        "\n",
        "\n",
        "    '''\n",
        "    super(UnetTransformer,self).__init__()\n",
        "    self.n_blocks = n_blocks\n",
        "    self.emb = nn.Embedding(n_tokens, d_model)\n",
        "    self.pos_enc = PositionalEncoding( d_model=d_model, dropout = emb_dropout)\n",
        "    for i in range(n_blocks):\n",
        "      vars(self)['_modules']['enc_'+str(i)] = EncoderBlock(d_model, n_heads, dim_feedforward, dropout)\n",
        "    for i in range(n_blocks):\n",
        "      vars(self)['_modules']['dec_'+str(i)] = DecoderBlock(d_model, n_heads, dim_feedforward, dropout)\n",
        "    self.output_layer = nn.Sequential( nn.Linear(d_model, d_model),\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(out_dropout),\n",
        "            nn.Linear(d_model, n_tokens)\n",
        "        )\n",
        "  def forward(self,x):\n",
        "    x_encoded = self.pos_enc(self.emb(x))\n",
        "    layers = vars(self)['_modules']\n",
        "    stack = [x_encoded]\n",
        "    x = layers['enc_0'](x_encoded)\n",
        "    for i in range(1,self.n_blocks):\n",
        "      stack.append(x)\n",
        "      x = layers['enc_'+str(i)](x)\n",
        "    stack.append(x)\n",
        "    x = layers['dec_0'](x,stack.pop(0))\n",
        "    for i in range(1,self.n_blocks):\n",
        "      x = layers['dec_'+str(i)](x,stack.pop(0))\n",
        "    return self.output_layer(x)\n",
        "\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Tuple\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import dataset"
      ],
      "metadata": {
        "id": "BcWK--CdaBXU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('spacy')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "# train_iter was \"consumed\" by the process of building the vocab,\n",
        "# so we have to create it again\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Args:\n",
        "        data: Tensor, shape [N]\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape [N // bsz, bsz]\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "\n",
        "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ],
      "metadata": {
        "id": "c2n815-3aGA4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(source: Tensor, i: int, desired_len: int) -> Tuple[Tensor, Tensor]:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        source: Tensor, shape [full_seq_len, batch_size]\n",
        "        i: int\n",
        "\n",
        "    Returns:\n",
        "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
        "        target has shape [seq_len * batch_size]\n",
        "    \"\"\"\n",
        "\n",
        "    seq_len = min(desired_len, source.shape[1] - 1 - i)\n",
        "    data = source[:,i:i+seq_len]\n",
        "    target = source[:,i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target\n",
        "get_batch(train_data,0,10)[0].shape"
      ],
      "metadata": {
        "id": "0CGLbgM1aS2m",
        "outputId": "dcab1fd0-2e2b-4081-b9fb-869b103d5e00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ntokens = len(vocab)\n",
        "print('n_tokens {}'.format(len(vocab)))\n",
        "model = UnetTransformer(n_blocks=n_blocks,n_tokens=ntokens,\\\n",
        "                        n_heads=n_heads, d_model = d_model,dim_feedforward = h_dims,\\\n",
        "                        dropout=dropout,out_dropout = out_dropout, emb_dropout=emb_dropout).to(device)\n",
        "pytorch_total_params = sum(p.numel()\n",
        "                        for p in model.parameters() if p.requires_grad)\n",
        "print('-' * 89)\n",
        "print(\n",
        "    '#'*12+f\" Training model with {pytorch_total_params/1000000:0.2F}M trainable parameters for {epochs:3d} epochs \"+'#'*12)\n",
        "print('-' * 89)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8us_WwAIaup5",
        "outputId": "bbf6277a-6de5-490e-bc10-1ce0710f5cb0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_tokens 33243\n",
            "-----------------------------------------------------------------------------------------\n",
            "############ Training model with 32.97M trainable parameters for 100 epochs ############\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicOpt:\n",
        "    def __init__(self, optimizer, schedular):\n",
        "        self.optimizer = optimizer\n",
        "        self.schedular = schedular\n",
        "        self._scalar = 1\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "    @property\n",
        "    def lr(self):\n",
        "      return self.optimizer.param_groups[0]['lr']*self._scalar\n",
        "\n",
        "    @property\n",
        "    def scalar(self):\n",
        "        return self._scalar\n",
        "\n",
        "    @scalar.setter\n",
        "    def scalar(self, scalar):\n",
        "        self._scalar = scalar\n",
        "\n",
        "\n",
        "    def schedule_step(self, val_loss):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def step(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class linearcycleWarmup(BasicOpt):\n",
        "    def __init__(self, optimizer, schedular, *args, **kwargs):\n",
        "        super().__init__(optimizer=optimizer, schedular=schedular)\n",
        "        self.use_scheduler = True\n",
        "\n",
        "       \n",
        "    def step(self):\n",
        "        lr_s = [p['lr'] for p in self.optimizer.param_groups]\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr']  = p['lr']*self._scalar             \n",
        "        self.optimizer.step()\n",
        "        for idx, p in enumerate(self.optimizer.param_groups):\n",
        "            p['lr'] = lr_s[idx]\n",
        "        try:\n",
        "          if self.use_scheduler:\n",
        "            self.schedular.step()\n",
        "        except Exception as e:\n",
        "          self.use_scheduler = False\n",
        "          for idx, p in enumerate(self.optimizer.param_groups):\n",
        "            p['lr'] = 0.0000088\n",
        "\n",
        "\n",
        "\n",
        "    def schedule_step(self, *args):\n",
        "        pass\n",
        "steps_per_epoch = train_data.size(1)//bptt+1\n",
        "total_steps = epochs*(steps_per_epoch)\n",
        "opt_args = {\n",
        "    'lr': 0,\n",
        "    'betas': (0.9, 0.98), 'eps': 1e-9, 'weight_decay': 1e-5\n",
        "}\n",
        "\n",
        "linear_args = {\n",
        "    'total_steps': total_steps,\n",
        "    'pct_start': 0.3, 'anneal_strategy': 'linear',\n",
        "    'three_phase': True, 'max_lr': 1e-3\n",
        "}\n",
        "opt = torch.optim.RAdam(model.parameters(),\n",
        "                        **opt_args)\n",
        "schedular_args = linear_args\n",
        "schedular = torch.optim.lr_scheduler.OneCycleLR(optimizer=opt, **schedular_args)"
      ],
      "metadata": {
        "id": "yk9NtX6gf9qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequence_length(bptt, use_var_length):\n",
        "    if not use_var_length:\n",
        "        return bptt\n",
        "    seq_len = bptt if np.random.random() < 0.95 else bptt // 2\n",
        "    seq_len = max(5, int(np.random.normal(seq_len, 5)))\n",
        "    seq_len = min(seq_len, bptt + 30)\n",
        "    return seq_len"
      ],
      "metadata": {
        "id": "Ph4OuVfI8gG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0  # learning rate\n",
        "optimizer = linearcycleWarmup(optimizer = opt, schedular=schedular )\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    #src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "\n",
        "    num_batches = train_data.shape[1] // bptt\n",
        "    i, batch = 0, 0\n",
        "    while i < train_data.size(1) - 1 - 1:\n",
        "        data, targets = get_batch(train_data, i, get_sequence_length(bptt, use_var_length=True))\n",
        "        batch_size = data.size(1)\n",
        "        # if batch_size != bptt:  # only on last batch\n",
        "        #     src_mask = src_mask[:batch_size, :batch_size]\n",
        "        output = model(data)\n",
        "        scale_lr = batch_size/bptt\n",
        "        optimizer.scalar = scale_lr\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = optimizer.lr\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.6f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}| seq_len {batch_size:5d}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "        batch += 1\n",
        "        i += batch_size\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    #src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(1) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i, bptt)\n",
        "            batch_size = data.size(1)\n",
        "            # if batch_size != bptt:\n",
        "            #     src_mask = src_mask[:batch_size, :batch_size]\n",
        "            output = model(data)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += batch_size * criterion(output_flat, targets).item()\n",
        "    return total_loss / (eval_data.size(1) - 1)"
      ],
      "metadata": {
        "id": "Gspv87NsaWha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model)\n",
        "    val_loss = evaluate(model, val_data)\n",
        "    val_ppl = math.exp(val_loss)\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    print('-' * 89)\n",
        "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "\n",
        "    #scheduler.step()"
      ],
      "metadata": {
        "id": "IHvZbtTJaa-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluate(model, test_data)\n",
        "test_ppl = math.exp(test_loss)\n",
        "print('-' * 89)\n",
        "print(f'test loss {test_loss:5.5f} | test ppl {test_ppl:8.5f}')\n",
        "print('-' * 89)"
      ],
      "metadata": {
        "id": "1Zgbkytp9Gqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "B9PEwV1-L9wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for rep in range(10):\n",
        "  epochs = 10             \n",
        "  lr = 5e-4               \n",
        "  clip = 0.5\n",
        "  bptt = 512\n",
        "  # best_val_loss = float('inf')\n",
        "  # best_model = None\n",
        "  steps_per_epoch = train_data.size(1)//bptt+1\n",
        "  total_steps = epochs*(steps_per_epoch)\n",
        "  opt_args = {\n",
        "      'lr': 0,\n",
        "      'betas': (0.9, 0.98), 'eps': 1e-9, 'weight_decay': 1e-5\n",
        "  }\n",
        "\n",
        "  linear_args = {\n",
        "      'total_steps': total_steps,\n",
        "      'pct_start': 0.1, 'anneal_strategy': 'linear',\n",
        "      'three_phase': True, 'max_lr': 1e-3\n",
        "  }\n",
        "  opt = torch.optim.RAdam(model.parameters(),\n",
        "                          **opt_args)\n",
        "  schedular_args = linear_args\n",
        "  schedular = torch.optim.lr_scheduler.OneCycleLR(optimizer=opt, **schedular_args)\n",
        "  optimizer = linearcycleWarmup(optimizer = opt, schedular=schedular )\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      epoch_start_time = time.time()\n",
        "      train(model)\n",
        "      val_loss = evaluate(model, val_data)\n",
        "      val_ppl = math.exp(val_loss)\n",
        "      elapsed = time.time() - epoch_start_time\n",
        "      print('-' * 89)\n",
        "      print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "      print('-' * 89)\n",
        "\n",
        "      if val_loss < best_val_loss:\n",
        "          best_val_loss = val_loss\n",
        "          del best_model\n",
        "          best_model = copy.deepcopy(model)"
      ],
      "metadata": {
        "id": "vxsIgBSvLhrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Not important"
      ],
      "metadata": {
        "id": "ON8LmbvYdMGU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndJCTLgBuQHp"
      },
      "source": [
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "  model.train()\n",
        "  num_classes = train_loader.dataset.num_categories\n",
        "  l = 0\n",
        "  acc = 0\n",
        "  pbar = tqdm(total = len(train_loader),position=0,leave=True)\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    target = target.to(device)\n",
        "\n",
        "    optimizer.zero_grad() \n",
        "    x, output_shifted = data\n",
        "    preds = model(x.to(device), output_shifted.to(device))       \n",
        "    loss = criterion(preds.view(-1,preds.size(-1)), target.view(-1),reduction=\"mean\")\n",
        "    loss.backward() \n",
        "    #nn.utils.clip_grad_norm(model.parameters(), clip)       \n",
        "    optimizer.step()\n",
        "    with torch.no_grad():\n",
        "      current_loss = loss.item()\n",
        "      l+= loss.item()\n",
        "      acc+=(preds.argmax(dim=-1) == target).float().mean().item()\n",
        "    pbar.set_description('training_step {} loss:{:3f}'.format(batch_idx,current_loss))\n",
        "    pbar.update()\n",
        "  acc = 100. * acc / (len(train_loader))\n",
        "  l = l/len(train_loader)\n",
        "  print('{0}: loss: {1:.3f} acc {2:.1f}'.format('train',l,acc))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOzqXY-WwNlr"
      },
      "source": [
        "def test( model, device, test_loader,criterion,mode='eval'):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  num_classes=test_loader.dataset.num_categories\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          target = target.to(device)\n",
        "          x, output_shifted = data\n",
        "          output = model(x.to(device), output_shifted.to(device))\n",
        "          test_loss += criterion(output.view(-1,output.size(-1)),\\\n",
        "                                        target.view(-1)).item()          \n",
        "          correct += (output.argmax(dim=-1) == target).float().mean().item()\n",
        "\n",
        "  loss = test_loss/len(test_loader)\n",
        "  acc = 100. * correct / len(test_loader)\n",
        "  print('{0}: loss: {1:.3f} acc {2:.1f}'.format(mode,loss,acc))\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raohC_7iRk0N"
      },
      "source": [
        "class ReverseDataset(data.Dataset):\n",
        "    def __init__(self, num_categories, seq_len, size):\n",
        "        super().__init__()\n",
        "        self.num_categories = num_categories\n",
        "        self.seq_len = seq_len\n",
        "        self.size = size\n",
        "\n",
        "        self.data = torch.randint(low=1, high=self.num_categories, size=(self.size, self.seq_len))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inp_data = self.data[idx]\n",
        "        labels = torch.flip(inp_data, dims=(0,))\n",
        "        labels_shifted = labels.roll(1,0)\n",
        "        labels_shifted[0] = torch.tensor(0)\n",
        "        return (inp_data,labels_shifted), labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ8jEEssRQX5"
      },
      "source": [
        "def main():\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.determinstic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    dataset = partial(ReverseDataset, 10, 16)\n",
        "    train_loader = data.DataLoader(dataset(50000), batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
        "    \n",
        "    val_loader   = data.DataLoader(dataset(1000), batch_size=test_batch_size)\n",
        "    test_loader  = data.DataLoader(dataset(10000), batch_size=test_batch_size)\n",
        "    model = UnetTransformer(n_blocks=n_blocks,input_dim=train_loader.dataset.num_categories,\\\n",
        "                            n_heads=n_heads,d_model = h_dims,num_classes=\\\n",
        "                            train_loader.dataset.num_categories,dim_feedforward = h_dims,\\\n",
        "                            dropout=dropout).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr= lr)\n",
        "    criterion =  F.cross_entropy\n",
        "    \n",
        "\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "       train(model, device, train_loader, optimizer,criterion)\n",
        "       test(model, device, val_loader,criterion)\n",
        "        \n",
        "    torch.save(model.state_dict(), \"model.h5\")\n",
        "    print('------------testing--------------')\n",
        "    test(model, device, test_loader,criterion,mode='test')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass\n",
        "    #main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}